{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP/j1R4X2HVmmoLJgpxRFW5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ajpYkj0vlW58","executionInfo":{"status":"ok","timestamp":1671825927671,"user_tz":-360,"elapsed":59179,"user":{"displayName":"Raptor Inc.","userId":"09770237195237218399"}},"outputId":"3e4fc3e0-43ac-4bc3-bba3-7373ac550ca6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)"]},{"cell_type":"code","source":["%%capture\n","\n","!pip install PyAudio\n","!pip install pydub\n","#!pip install pyaudio\n","!pip install noisereduce\n","!pip install json-tricks"],"metadata":{"id":"npZlAOF7lzc5","executionInfo":{"status":"ok","timestamp":1671828462813,"user_tz":-360,"elapsed":22020,"user":{"displayName":"Raptor Inc.","userId":"09770237195237218399"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["%%capture\n","import os\n","from json_tricks import load\n","\n","import numpy as np\n","\n","import librosa\n","from pydub import AudioSegment, effects\n","import noisereduce as nr\n","\n","import tensorflow as tf\n","import keras\n","from keras.models import model_from_json\n","from keras.models import load_model\n","\n","import matplotlib.pyplot as plt"],"metadata":{"id":"lbMnT9Cql2dw","executionInfo":{"status":"ok","timestamp":1671825984589,"user_tz":-360,"elapsed":9097,"user":{"displayName":"Raptor Inc.","userId":"09770237195237218399"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["saved_model_path = '/content/drive/My Drive/Colab Notebooks/model8723.json'\n","saved_weights_path = '/content/drive/My Drive/Colab Notebooks/model8723_weights.h5'\n","\n","#Reading the model from JSON file\n","with open(saved_model_path, 'r') as json_file:\n","    json_savedModel = json_file.read()\n","    \n","# Loading the model architecture, weights\n","model = tf.keras.models.model_from_json(json_savedModel)\n","model.load_weights(saved_weights_path)\n","\n","# Compiling the model with similar parameters as the original model.\n","model.compile(loss='categorical_crossentropy', \n","                optimizer='RMSProp', \n","                metrics=['categorical_accuracy'])\n","\n","print(model.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JcC0HeLol33z","executionInfo":{"status":"ok","timestamp":1671825996814,"user_tz":-360,"elapsed":2381,"user":{"displayName":"Raptor Inc.","userId":"09770237195237218399"}},"outputId":"48ec63ef-a604-40e3-8108-0171f2356f03"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 951, 64)           20480     \n","                                                                 \n"," lstm_1 (LSTM)               (None, 64)                33024     \n","                                                                 \n"," dense (Dense)               (None, 8)                 520       \n","                                                                 \n","=================================================================\n","Total params: 54,024\n","Trainable params: 54,024\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["def preprocess(file_path, frame_length = 2048, hop_length = 512):\n","    '''\n","    A process to an audio .wav file before execcuting a prediction.\n","      Arguments:\n","      - file_path - The system path to the audio file.\n","      - frame_length - Length of the frame over which to compute the speech features. default: 2048\n","      - hop_length - Number of samples to advance for each frame. default: 512\n","\n","      Return:\n","        'X_3D' variable, containing a shape of: (batch, timesteps, feature) for a single file (batch = 1).\n","    ''' \n","    # Fetch sample rate.\n","    _, sr = librosa.load(path = file_path, sr = None)\n","    # Load audio file\n","    rawsound = AudioSegment.from_file(file_path, duration = None) \n","    # Normalize to 5 dBFS \n","    normalizedsound = effects.normalize(rawsound, headroom = 5.0) \n","    # Transform the audio file to np.array of samples\n","    normal_x = np.array(normalizedsound.get_array_of_samples(), dtype = 'float32') \n","    # Noise reduction                  \n","    final_x = nr.reduce_noise(normal_x, sr=sr, use_tensorflow=True)\n","        \n","        \n","    f1 = librosa.feature.rms(final_x, frame_length=frame_length, hop_length=hop_length, center=True, pad_mode='reflect').T # Energy - Root Mean Square\n","    f2 = librosa.feature.zero_crossing_rate(final_x, frame_length=frame_length, hop_length=hop_length,center=True).T # ZCR\n","    f3 = librosa.feature.mfcc(final_x, sr=sr, S=None, n_mfcc=13, hop_length = hop_length).T # MFCC   \n","    X = np.concatenate((f1, f2, f3), axis = 1)\n","    \n","    X_3D = np.expand_dims(X, axis=0)\n","    \n","    return X_3D"],"metadata":{"id":"41XiUIe_mGa3","executionInfo":{"status":"ok","timestamp":1671826058155,"user_tz":-360,"elapsed":470,"user":{"displayName":"Raptor Inc.","userId":"09770237195237218399"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Emotions list is created for a readable form of the model prediction.\n","\n","emotions = {\n","    0 : 'neutral',\n","    1 : 'calm',\n","    2 : 'happy',\n","    3 : 'sad',\n","    4 : 'angry',\n","    5 : 'fearful',\n","    6 : 'disgust',\n","    7 : 'suprised'   \n","}\n","emo_list = list(emotions.values())\n","\n","def is_silent(data):\n","    # Returns 'True' if below the 'silent' threshold\n","    return max(data) < 100"],"metadata":{"id":"hQ7WwYsUmThG","executionInfo":{"status":"ok","timestamp":1671826079763,"user_tz":-360,"elapsed":458,"user":{"displayName":"Raptor Inc.","userId":"09770237195237218399"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!pip3 install pyaudio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-IKYr8bvwgmi","executionInfo":{"status":"ok","timestamp":1671828891178,"user_tz":-360,"elapsed":8508,"user":{"displayName":"Raptor Inc.","userId":"09770237195237218399"}},"outputId":"675fc03c-e2ea-416a-f921-0876ff9c3848"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyaudio\n","  Using cached PyAudio-0.2.12.tar.gz (42 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: pyaudio\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pyaudio \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n","\u001b[31m  ERROR: Failed building wheel for pyaudio\u001b[0m\u001b[31m\n","\u001b[0mFailed to build pyaudio\n","\u001b[31mERROR: Could not build wheels for pyaudio, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2BF3fAaZxC4w","executionInfo":{"status":"ok","timestamp":1671829049661,"user_tz":-360,"elapsed":13668,"user":{"displayName":"Raptor Inc.","userId":"09770237195237218399"}},"outputId":"14d108ff-28b9-4d82-fb6c-d99c64fae798"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","libasound2-dev is already the newest version (1.1.3-5ubuntu0.6).\n","ffmpeg is already the newest version (7:3.4.11-0ubuntu0.1).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","Suggested packages:\n","  portaudio19-doc\n","The following NEW packages will be installed:\n","  libportaudio2 libportaudiocpp0 portaudio19-dev\n","0 upgraded, 3 newly installed, 0 to remove and 20 not upgraded.\n","Need to get 184 kB of archives.\n","After this operation, 891 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libportaudio2 amd64 19.6.0-1 [64.6 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libportaudiocpp0 amd64 19.6.0-1 [15.1 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 portaudio19-dev amd64 19.6.0-1 [104 kB]\n","Fetched 184 kB in 1s (172 kB/s)\n","Selecting previously unselected package libportaudio2:amd64.\n","(Reading database ... 124016 files and directories currently installed.)\n","Preparing to unpack .../libportaudio2_19.6.0-1_amd64.deb ...\n","Unpacking libportaudio2:amd64 (19.6.0-1) ...\n","Selecting previously unselected package libportaudiocpp0:amd64.\n","Preparing to unpack .../libportaudiocpp0_19.6.0-1_amd64.deb ...\n","Unpacking libportaudiocpp0:amd64 (19.6.0-1) ...\n","Selecting previously unselected package portaudio19-dev:amd64.\n","Preparing to unpack .../portaudio19-dev_19.6.0-1_amd64.deb ...\n","Unpacking portaudio19-dev:amd64 (19.6.0-1) ...\n","Setting up libportaudio2:amd64 (19.6.0-1) ...\n","Setting up libportaudiocpp0:amd64 (19.6.0-1) ...\n","Setting up portaudio19-dev:amd64 (19.6.0-1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n"]}]},{"cell_type":"code","source":["!pip install pyaudio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jP-fPHpWxyxH","executionInfo":{"status":"ok","timestamp":1671829206743,"user_tz":-360,"elapsed":4129,"user":{"displayName":"Raptor Inc.","userId":"09770237195237218399"}},"outputId":"9bf1c95e-a30f-4fcd-f4ee-166936cc54ef"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyaudio in /usr/local/lib/python3.8/dist-packages (0.2.12)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import pyaudio\n","import wave\n","from array import array\n","import struct\n","import time\n","\n","# Initialize variables\n","RATE = 24414\n","CHUNK = 512\n","RECORD_SECONDS = 7.1\n","\n","FORMAT = pyaudio.paInt32\n","CHANNELS = 1\n","WAVE_OUTPUT_FILE = \"/content/drive/My Drive/Colab Notebooks/output.wav\"\n","\n","# Open an input channel\n","p = pyaudio.PyAudio()\n","stream = p.open(format=FORMAT,\n","                channels=CHANNELS,\n","                rate=RATE,\n","                input=True,\n","                frames_per_buffer=CHUNK)\n","\n","\n","# Initialize a non-silent signals array to state \"True\" in the first 'while' iteration.\n","data = array('h', np.random.randint(size = 512, low = 0, high = 500))\n","\n","# SESSION START\n","print(\"** session started\")\n","total_predictions = [] # A list for all predictions in the session.\n","tic = time.perf_counter()\n","\n","while is_silent(data) == False:\n","    print(\"* recording...\")\n","    frames = [] \n","    data = np.nan # Reset 'data' variable.\n","\n","    timesteps = int(RATE / CHUNK * RECORD_SECONDS) # => 339\n","\n","    # Insert frames to 'output.wav'.\n","    for i in range(0, timesteps):\n","        data = array('l', stream.read(CHUNK)) \n","        frames.append(data)\n","\n","        wf = wave.open(WAVE_OUTPUT_FILE, 'wb')\n","        wf.setnchannels(CHANNELS)\n","        wf.setsampwidth(p.get_sample_size(FORMAT))\n","        wf.setframerate(RATE)\n","        wf.writeframes(b''.join(frames))\n","\n","    print(\"* done recording\")\n","\n","    x = preprocess(WAVE_OUTPUT_FILE) # 'output.wav' file preprocessing.\n","    # Model's prediction => an 8 emotion probabilities array.\n","    predictions = model.predict(x, use_multiprocessing=True)\n","    pred_list = list(predictions)\n","    pred_np = np.squeeze(np.array(pred_list).tolist(), axis=0) # Get rid of 'array' & 'dtype' statments.\n","    total_predictions.append(pred_np)\n","    \n","    # Present emotion distribution for a sequence (7.1 secs).\n","    fig = plt.figure(figsize = (10, 2))\n","    plt.bar(emo_list, pred_np, color = 'darkturquoise')\n","    plt.ylabel(\"Probabilty (%)\")\n","    plt.show()\n","    \n","    max_emo = np.argmax(predictions)\n","    print('max emotion:', emotions.get(max_emo,-1))\n","    \n","    print(100*'-')\n","    \n","    # Define the last 2 seconds sequence.\n","    last_frames = np.array(struct.unpack(str(96 * CHUNK) + 'B' , np.stack(( frames[-1], frames[-2], frames[-3], frames[-4],\n","                                                                            frames[-5], frames[-6], frames[-7], frames[-8],\n","                                                                            frames[-9], frames[-10], frames[-11], frames[-12],\n","                                                                            frames[-13], frames[-14], frames[-15], frames[-16],\n","                                                                            frames[-17], frames[-18], frames[-19], frames[-20],\n","                                                                            frames[-21], frames[-22], frames[-23], frames[-24]),\n","                                                                            axis =0)) , dtype = 'b')\n","    if is_silent(last_frames): # If the last 2 seconds are silent, end the session.\n","        break\n","\n","# SESSION END        \n","toc = time.perf_counter()\n","stream.stop_stream()\n","stream.close()\n","p.terminate()\n","wf.close()\n","print('** session ended')\n","\n","# Present emotion distribution for the whole session.\n","total_predictions_np =  np.mean(np.array(total_predictions).tolist(), axis=0)\n","fig = plt.figure(figsize = (10, 5))\n","plt.bar(emo_list, total_predictions_np, color = 'indigo')\n","plt.ylabel(\"Mean probabilty (%)\")\n","plt.title(\"Session Summary\")\n","plt.show()\n","\n","print(f\"Emotions analyzed for: {(toc - tic):0.4f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"LBoRw4xoscwa","executionInfo":{"status":"error","timestamp":1671829985075,"user_tz":-360,"elapsed":453,"user":{"displayName":"Raptor Inc.","userId":"09770237195237218399"}},"outputId":"c3295314-78f8-4e3a-9d2b-fb5e27b038bb"},"execution_count":38,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-e531069caaca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Open an input channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m stream = p.open(format=FORMAT,\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCHANNELS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyaudio.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \"\"\"\n\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_streams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyaudio.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, PA_manager, rate, channels, format, input, output, input_device_index, output_device_index, frames_per_buffer, start, input_host_api_specific_stream_info, output_host_api_specific_stream_info, stream_callback)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;31m# calling pa.open returns a stream object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_latency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputLatency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno -9996] Invalid input device (no default output device)"]}]}]}